\section{Experiments}

To demonstrate the flexibility that the framework allows, an extensive comparison of 12 different agent types will be performed across two
adversarial games; Connect Four, and Nim. Since the framework can be generalized to work on non-adversarial games as well, a brief showcase of two non-adversarial agents in the game 2048 will also be included.

\subsection{Agents}

Figure \ref{fig:minimax_inheritance} and \ref{fig:mcts_inheritance} show the agents as nodes in an inheritance graph. If a node does not specify a certain component function, that function is inherited from the parent:

\input{tikz/minimax_inheritance.tex}

\input{tikz/mcts_inheritance.tex}

The agents are split into two groups, MiniMax based, and MCTS based. Note that MiniMax from MCTS Tree inherits from MCTS, but is classified as a MiniMax based agent. This is due to the fact that, for the purposes of the experiments, agents are classified by the information they use in \gbm. The two groups can be seen below, along with shorthand names that will be used in figures:

\begin{multicols}{2}
    \subsubsection*{MiniMax Based}
    \begin{itemize}
        \item Iterative Deepening: ID
        \item Iterative Deepening w/ $\alpha\beta$-pruning: ID-AB
        \item Iterative Deepening w/ Simulation: ID-Sim
        \item Iterative Deepening w/Beam Search: ID-BS
        \item Best First MiniMax: BFMM
        \item MiniMax from MCTS Tree: MM-MCT
    \end{itemize}
    \columnbreak
    \subsubsection*{MCTS Based}
    \begin{itemize}
        \item Monte Carlo Tree Search: MC
        \item MCTS w/ Static Rollout: MC-SR
        \item MCTS w/ Partial Expansion: MC-PE
        \item Statically Weighted MCTS: SW-MC
        \item MiniMax Weighted MCTS: MW-MC
        \item MCTS w/ Progressive Pruning: MC-PP
    \end{itemize}
\end{multicols}

\newpage

\subsection{Environments}

\subsubsection{Connect Four}
Connect Four is a board filling game typically played on a rectangular board with $7$ columns and $6$ rows. Players take turns dropping one piece into a non-full column, where the piece will fall until it hits the bottom, or another piece. The first player to align four of their pieces horizontally, vertically, diagonally, or antidiagonally wins. The game is solved, and from the initial position of an empty board, the first player can force a win. The game tree complexity of Connect Four is given in \cite{Allis1994} as $10^{21}$. Connect Four is a good candidate for exploring adversarial search algorithms since the states can be easily represented as bitboards, allowing for fast move making by OR-ing in new pieces as well as fast utility calculation. The fact that it is solved also makes it possible to compare agent performance to optimal play.

\subsubsection{Nim}
Nim is a combinatorial game where players take turns removing stones from one of multiple heaps on the board. A player can take any amount of stones from a single stack, but must take at least one. The player who takes the last stone wins. Nim is also solved, and in contrast to Connect Four it is solved in a way that makes desinging an optimal evaluation function trivial. A state is a forced win for the current player if the binary digital sum of all the heap sizes is nonzero. The binary digital sum is simply the bitwise XOR value of all its inputs, and since it solves Nim in this way it is often called the nim-sum. From a state with a nonzero nim-sum it is always possible to make a move resulting in a nim-sum of zero, and from a nim-sum of zero it is impossible to remain at zero. In this paper Nim is played on a board with initial heap sizes $\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$, which is a forced win for the first player under optimal play. The game tree complexity for Nim with this initial state is determined by a brute force enumeration to be $5.16 \cdot 10^{47}$.

\subsubsection{2048}
As the only non-adversarial game examined in this paper, 2048 is a single player puzzle game, where the objective is to combine many smaller tiles into the titular 2048 tile. While the 2048 tile is officially declared a win, it is possible to contiune past it to create even bigger tiles. The game is played on a $4$ by $4$ grid, with the following rules: On each turn including the first, a tile spawns in an empty spot. The placement is uniformly distributed, and the value of the tile is $2$ with a $90\%$ chance, and $4$ with a $10\%$ chance. In \cite{Strandby2016} Strandby sets an experimental value of the game tree size at $9.26 \cdot 10^{2139}$, which is many times larger than the two other environments. This has to do with the maximum depth being much greater than both Connect Four and Nim, and the fact that chance nodes also grow the search tree exponentially, effectively doubling the depth compared to a deterministic environment.

\newpage
\subsection{Comparison}
Firstly, the agents within each group will play against each other
such that each agent type plays against all other agent types, as well
as against itself. Each matchup will consist of $250$ games. Since both groups are of size 6, this will result in $2 \cdot 6^2 \cdot 250 = 18000$ games in total. This initial comparison will only be performed in Connect Four.

From each group, the top two agents will be picked out, forming a new group of four agents. These agents will also be paired in all combinations with $250$ games in each matchup, for a total of $4000$ games. This will be done on both 
Connect Four and Nim.

To demonstrate that the framework also generalizes to non-adversarial environments, an ExpectiMax agent and an MCTS agent will be tested on 2048. None of the adversarial agents can be used directly (at least not with good results) since they all assume that the min-player will be actively resisting their goals, while in reality the min-player will play the role of the environment and act according to the environment rules. The modified agents are as follows:

\input{tikz/maximizer_inheritance.tex}
