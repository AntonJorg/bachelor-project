\section{Discussion}

The aim of this paper is to introduce a general tree search framework, and not to design high performance tree search agents. Therefore the main focus of this discussion will be on the merits and pitfalls of using EGTS in the experimental setting, and not on the actual results of the experiments. That being said, a short interpretation of the results will be offered first.

In domains without a perfect evaluation function, MCTS based methods significantly outperformed their MiniMax/ExpectiMax counterparts (Figure \ref{fig:top_four_results_average}). Since real time perfect solvers are available for Connect Four \cite{Pons2019}, it is not unreasonable to expect the MiniMax based agents to be the dominant players in this environment. Combining this with the fact that Iterative Deepening w/ Simulation outperforms Iterative Deepening w/ $\alpha\beta$-pruning, it looks like the evaluation function is just not very accurate.

The same can be said about 2048, where due to time constraints the evaluation function is simply the score of the position. This evaluation does not say anything about how hard that position is to continue from, and is therefore not a good evaluation either. Strandby \cite{Strandby2016} did an extensive comparison of evaluation functions for 2048, and found a ~4 times increase in average points when moving from a points only evaluation to an optimized linear combination of several more advanced evaluation functions. This was even when the points only version searched to depth 5, and the optimized version only searched to depth 3, which suggests that there is much potential left in the ExpectiMax agent.

On the other end of the spectrum is the perfect evaluation function in Nim, which is clearly reflected in the $100\%$ winrate of Best First MiniMax, which is the only agent in the top four group with access to the evaluation function.

Inheritance is in most cases an elegant way to describe how EGTS algorithms relate to each other, and just like inheritance in object oriented programming it makes it possible to adjust behavior of a large set of agents easily, by changing behaviour in an ancestor agent. However, some cases could benefit from more advanced inheritance handling. The most obvious case is perhaps the one where a function does the work of two previously defined functions, e.g. \textproc{BackpropagateSumAndMiniMax} just calls \textproc{BackpropagateSum} and \textproc{BackpropagateMiniMax}. Another case is when the control flow functions (the \textproc{Should}- functions) of a child could be perfectly described as the result of a logical operator applied to that same function in its parents. As an example, consider a depth limited $\alpha\beta$-pruning agent created by inheriting from a non-depth limited $\alpha\beta$-pruning agent and a depth limited MiniMax agent. The depth limited $\alpha\beta$-pruning agent would need to specify its own \shbp function as \textproc{IfDepthReachedOrFullyExpanded}, even though one parent uses \textproc{IfFullyExpanded} and the other uses \textproc{IfDepthReached}. The last case is when a function effectively wraps the function that it overrides in its parent. This is observed especially in the \expand functions of the MiniMax based agents, where \textproc{ExpandBeam} wraps \textproc{ExpandNextAlphaBeta}, which wraps \textproc{ExpandNextDepthLimited}, which finally wraps \textproc{ExpandNext}. All of these three cases would probably have to be handled differently, and it is not immediately clear how that could be achieved without overly complicating the overall framework, even though inheritance is seperate from the pseudocode and would therefore not affect it. In any case it seems as a 'nice to have' feature that could be developed if/when the idea of generalizing tree search has matured further.

%Balance between descriptiveness and generalization

In Section \ref{sec:generalizing} a choice was made to model tree search with an iterative algorithm, which is subsequently what EGTS uses. While an iterative approach is in many cases the most conceptually simple, trees as a data structure lend themselves naturally to recursion, and so one might ask if the iterative approach was really the right choice. It is of course impossible to answer without having a recursive framework to compare to, but since all the tree-traversing component functions; \select, \bp, and \trim use recursion internally in most cases, there is an argument that having the outer framework be iterative leaves a lot of flexibility in the hands of the ones who actually have to implement algorihtms using it. 

In the introduction, AlphaGo was mentioned as a major breakthrough in adversarial tree search. Even though the overall pipeline of training AlphaGo includes supervised learning on a database of board positions from high-level games and reinforcement learning via self play, the actual search algorithm in AlphaGo can be implemented in EGTS. It is almost the same as normal MCTS, but it uses a policy network to guide selection, a value network as an addition to simulations, and a fast rollout policy such that its rollouts are not performed with uniformly sampled actions. All of these things are allowed in EGTS, since a trained neural network is just a function like any other, and they operate locally in the search tree, thereby not requiring any information that an EGTS imlementation would not have.

Early on in the project the number of agents planned was much smaller, but as the process got closer and closer to the final EGTS formulation, it became clear that the framework itself would make new agents easier to implement and debug, allowing for a greater suite of agents to be tested. This in itself supports one of the key goals in this paper, enabling easier implementation and experimentation with adversarial agents.

It is a common approach in education to break complex subjects into smaller parts, e.g. if you want to understand neural networks it helps to know calculus and linear algebra beforehand. It seems probable that the unification of adversarial search algorithms into a single, modular framework would also help students to learn this subject by naturally breaking algorithms into smaller more manageable pieces. Apart from being able to learn the algorithms one component function at a time, EGTS also allows for easier retention by relating the algorithms through inheritance. Instead of remembering algorithm X and Y as separate entities, a student can say "X is like Y except its \expand function is \textproc{Foo} instead of \textproc{Bar}".

\newpage
\section{Conclusion and Future Work}

Overall, the EGTS framework is a first step on the road to generalizing adversarial tree search, and there is much work still to be done. From the work done in this paper it is clear that EGTS works as a framework for implementing agents, and that it even makes it easier in some aspects. 

The main place for improvement in its current state is in its expression of the roles of the individual component functions. Right now it takes a whole page of additional data structure pseudocode to get the message across, while in a perfect world all that would be needed is the pseudocode of the main framework. It might be possible to restructure the framework in a way that requires fewer component functions, and there is also the possibility that the best way to generalize adversarial tree search is completely different from the one described here.

There are many things that could be added to EGTS, some that might fit in the current version, and some that would be additional extensions of the framework. An addition to the current version could be allowing \gbm to be substituted for a \textproc{GetValue} function that returned the value of the root state. This would make the entire EGTS agent a function $f:S \to \mathbb{R}^n$ from the state space to $n$-tuples of real numbers, and would allow other EGTS agents to use them as \eval functions, thereby making the description of nested algorithms easier. A completely new extension could be support for ensemble methods. Right now it would be easy to just have several EGTS agents and decide on moves from their combined outputs, but if ensemble results were needed inside the search that would be difficult to handle at the moment.

Taking all this into account, the EGTS framework as presented is a substantial first step into generalizing adversarial search algorithms, but a first step nonetheless, leaving plenty of room for further improvement and refinement, until one day there exist a mature and comprehensive unified adversarial search framework.